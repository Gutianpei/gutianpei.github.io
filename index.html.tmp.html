
<!doctype html>
<html>

<head>
	<meta name="google-site-verification" content="zTvaPIARk2z5erZsE_yyEIuPe3r5Z1kwHtZ662ncmLU" />
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>Tianpei Gu 顾天培</title>

	<link rel="stylesheet" href="stylesheets/styles.css">
	<link rel="stylesheet" href="stylesheets/pygment_trac.css">
	<meta name="viewport" content="width=device-width">
	<link rel="icon" type="image/png" href="images/icon.png">
	<!--[if lt IE 9]>
		<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
</head>

<body>
	<div class="wrapper">
		<header>
			<h2>Tianpei Gu 「顾天培」</h2>
			<p></p>
<!-- 			<p>Research Ass @ Tsinghua University</p> -->
<!-- 			<p>Research Intern @ SenseTime Research</p> -->
			<img src="images/tianpei.JPG" alt="Photo @ UMD.">
			<p>
				<b>Email:</b> <a href="mailto:brucegu@umd.edu">gutianpei@ucla.edu</a><br>
				<b>Github:</b> <a href="https://github.com/Gutianpei" , target="_blank">https://github.com/Gutianpei</a><br>
				<b>LinkedIn:</b> <a href="https://www.linkedin.com/in/tianpei-gu-973904129/ ,
					target="_blank">https://www.linkedin.com/in/tianpei-gu-973904129/</a><br>
			</p>
			<img src="images/umd.jpg" alt="umd." height=63 weight = 63>
			<img src="images/thu.png" alt="thu." height=60 weight = 60>
			<img src="images/ucla.png" alt="ucla." height=60 weight = 60>
			

		</header>
		<section>
			<h1>About Me</h1>
			<p> I'm a first year Master student at <b>UCLA</b>, working closely with <a href="https://boleizhou.github.io/">Prof. Bolei Zhou</a>. I did research at <a href="http://ivg.au.tsinghua.edu.cn/">Intelligent Vision Group (IVG)</a>,  <b>Tsinghua University</b>, under the guidance of <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a> and <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Dr. Guangyi Chen</a>. I also worked at <b>SenseTime Research</b> as an intern. In December 2020, I received B.S. degree in Computer Science and Mathematics at the <b>University of Maryland</b>. 
				My research interest is in <b>Computer Vision</b>, especially <b>Generative Models</b> and other interesting problems. 
				<!-- 				You can find my <a href="docs/GTP CV.pdf" target="_blank">resume</a> here. -->
			</p>
			<h1>Education</h1>
			
			<h3>University of California, Los Angeles, CA, USA</h3>
			<ul>
				<li>Master of Engineering, Expected: December 2022</li>
				<li>TA for computer vision course</li>
			</ul>

			<h3>University of Maryland at College Park, MD, USA</h3>
			<ul>
				<li>Bachelor of Science in Computer Science</li>
				<li>Bachelor of Science in Mathematics</li>
			</ul>

			<h1>Publications</h1>
			<td width="100%" valign="center",style="white-space:nowrap;">
<!-- 				<strong>[1] Person Re-Identification via Attention Pyramid</strong> -->
<!-- 				<br> -->
<!-- 				Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-an Bao, Jie Zhou -->
<!-- 				<br> -->
<!-- 				<em>Submitted to IEEE Transcations on Image Processing(<strong>TIP</strong>), 2020</em> -->
<!-- 				<p>We designed a novel attention pyarmid structure to help the network focus more on local feature while keep the global representation.</p> -->
					
					<tr>
						
						<td width="75%" valign="center",style="white-space:nowrap;">
							<papertitle><strong>[1] MID: Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion</strong></papertitle>
							<br>
							<strong>Tianpei Gu</strong>*, Guangyi Chen*, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou, Jiwen Lu
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<b><strong>CVPR</strong></b>)</em>, 2022
							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
							 								<img style="width:100%;max-width:100%;height:50" src="file:///Users/gutianpei/Desktop/gutianpei.github.io/images/pub/MID.png" alt="dise"> 
							 							</td> 

							<a href="https://arxiv.org/abs/2203.13777">[arxiv]</a> <a href="https://github.com/Gutianpei/MID">[code]</a> 
							<br>
						</td>
					</tr>

					<tr>
						
						<td width="75%" valign="center",style="display:inline">
							<papertitle><strong>[2] Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory</strong></papertitle>
							<br>
							Li Siyao, Wenjiang Yu, <strong>Tianpei Gu</strong>, Chunze Lin, QUan Wang, Chen Qian, Chen Change Loy, Ziwen Liu
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<strong>CVPR</strong>)</em>, 2022
							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
							 	<img style="width:100%;max-width:100%" src="file:///Users/gutianpei/Desktop/gutianpei.github.io/images/pub/Bailando.png" alt="dise"> 
							 </td> 
							<a href="">[arxiv]</a> <a href="code">[code]</a> 
							<br>
							<p></p>
							
						</td>
					</tr>
					
					
					
					
					
					
					<tr>
						
						<td width="75%" valign="center">
							<papertitle><strong>[3] Person Re-identification via Attention Pyramid</strong></papertitle>
							<br>
							Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-An Bao, and Jie Zhou
							<br>
							<em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2021
							<br>
 							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
 								<img style="width:100%;max-width:100%" src="file:///Users/gutianpei/Desktop/gutianpei.github.io/images/pub/APNET.png" alt="dise"> 
 							</td> 
							<a href="https://chengy12.github.io/files/TIP-24326-2021R2.pdf">[PDF]</a> <a href="https://chengy12.github.io/files/TIP-24326-2021supp.pdf">[Supp]</a> <a href="https://github.com/gutianpei/APNet">[Code]</a> 
							<br>
							<p></p>
							<p>We propose attention pyramid networks by the "split-attend-merge-stack" principle to jointly learn the attentions under different scales and obtain superior performance on many person re-identification datasets.
							</p>
						</td>
					</tr>
			
			
			</td>

			
			
			<h1>Field Experience</h1>
			
			<h3>SenseTime Research</h3>
			Computer Vision Research Intern
			<ul>
				<li>Build an end-to-end image generation pipeline with StyleGAN to produce massive high-quality stylized image with model blending.</li>
				<li>Main contributor of the product which transferring human face image into multiple style (now 10+).</li>
				<li>Develop a pipeline of “Inversion-Editing-Stylization” for human face, which the editing part can receive a certain attribute selection or a text prompt.</li>
				<li>Assisted to implement the project of music to dance generation</li>
			</ul>

			
			
			
			<h3>Beijing Photon Dance Tech Inc.</h3>
			Co-Founder, Algorithm Engineer
			<ul>
				<li>Founded in Skywork Team, Tsinghua University.</li>
				<li>Proposed an end-to-end solution from extracted 3D point cloud with multiple views to automatic motion difference evaluating. Participated in multi-view point cloud calibration and developing of DL-based merging algorithm.</li>
				<li>Our team just receive the Pre-A Investment.</li>
			</ul>

			<h1>Professional Skills</h1>
			<p><b>Programming Language (ranked by proficiency):</b> Python, Java, C, C++, Matlab, Git, Shell</p>
			<p><b>Deep Learning Framework:</b> Keras, PyTorch, TensorFlow </p>

			<h1>Service</h1>
				<li>Reviewer for CVPR2022</li>

	</div>
	<script src="javascripts/scale.fix.js"></script>
	<script async src="http://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>
</body>

</html>
