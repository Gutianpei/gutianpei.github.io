
<!doctype html>
<html>

<head>
	<meta name="google-site-verification" content="zTvaPIARk2z5erZsE_yyEIuPe3r5Z1kwHtZ662ncmLU" />
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>Tianpei Gu 顾天培</title>

	<link rel="stylesheet" href="stylesheets/styles.css">
	<link rel="stylesheet" href="stylesheets/pygment_trac.css">
	<meta name="viewport" content="width=device-width">
	<link rel="icon" type="image/png" href="images/icon.png">
	<!--[if lt IE 9]>
		<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
</head>

<body>
	<div class="wrapper">
		<header>
			<h2>Tianpei Gu 「顾天培」</h2>
			<p></p>
<!-- 			<p>Research Ass @ Tsinghua University</p> -->
<!-- 			<p>Research Intern @ SenseTime Research</p> -->
			<img src="images/tianpei.JPG" alt="Photo @ UMD.">
			<p>
				<b>Email:</b> <a href="mailto:brucegu@umd.edu">gutianpei@ucla.edu</a><br>
				<b>Github:</b> <a href="https://github.com/Gutianpei" , target="_blank">https://github.com/Gutianpei</a><br>
				<b>LinkedIn:</b> <a href="https://www.linkedin.com/in/tianpei-gu-973904129/ ,
					target="_blank">https://www.linkedin.com/in/tianpei-gu-973904129/</a><br>
			</p>
			<img src="images/umd.jpg" alt="umd." height=63 weight = 63>
			<img src="images/thu.png" alt="thu." height=60 weight = 60>
			<img src="images/ucla.png" alt="ucla." height=60 weight = 60>
			

		</header>
		<section>
			<h1>About Me</h1>
			<p> I'm a first year Master student at <b>UCLA</b>, working closely with <a href="https://boleizhou.github.io/">Prof. Bolei Zhou</a>. I did research at <a href="http://ivg.au.tsinghua.edu.cn/">Intelligent Vision Group (IVG)</a>,  <b>Tsinghua University</b>, under the guidance of <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a> and <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Dr. Guangyi Chen</a>. I also worked at <b>SenseTime Research</b> as an intern. In December 2020, I received B.S. degree in Computer Science and Mathematics at the <b>University of Maryland</b>. 
				My research interest is in <b>Computer Vision</b>, especially <b>Generative Models</b> and other interesting problems. 
				<!-- 				You can find my <a href="docs/GTP CV.pdf" target="_blank">resume</a> here. -->
			</p>
			<h1>Education</h1>
			
			<h3>University of California, Los Angeles, CA, USA</h3>
			<ul>
				<li>Master of Engineering, Expected: December 2022</li>
				<li>TA for computer vision course</li>
			</ul>

			<h3>University of Maryland at College Park, MD, USA</h3>
			<ul>
				<li>Bachelor of Science in Computer Science</li>
				<li>Bachelor of Science in Mathematics</li>
			</ul>

			<h1>Publications</h1>
			<td width="100%" valign="center",style="white-space:nowrap;">
<!-- 				<strong>[1] Person Re-Identification via Attention Pyramid</strong> -->
<!-- 				<br> -->
<!-- 				Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-an Bao, Jie Zhou -->
<!-- 				<br> -->
<!-- 				<em>Submitted to IEEE Transcations on Image Processing(<strong>TIP</strong>), 2020</em> -->
<!-- 				<p>We designed a novel attention pyarmid structure to help the network focus more on local feature while keep the global representation.</p> -->
					
					<tr>
						
						<td width="75%" valign="center",style="white-space:nowrap;">
							<papertitle><strong>[1] MID: Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion</strong></papertitle>
							<br>
							<strong>Tianpei Gu</strong>*, Guangyi Chen*, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou, Jiwen Lu
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<b><strong>CVPR</strong></b>)</em>, 2022
							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
							 								<img style="width:100%;max-width:100%;height:50" src="./images/pub/MID.pdf" alt="dise"> 
							 							</td> 
							
<!-- 							<br> -->
<!-- 							<td style="padding:20px;width:30%;max-width:30%" align="center"> -->
<!--  								<img style="width:100%;max-width:100%" src="images/pub/APNET.pdf" alt="dise"> --> 
<!--  							</td> -->
<!-- 							<a href="https://chengy12.github.io/files/TIP-24326-2021R2.pdf">[PDF]</a> <a href="https://chengy12.github.io/files/TIP-24326-2021supp.pdf">[Supp]</a> <a href="https://github.com/gutianpei/APNet">[Code]</a>  -->
<!-- 							<br> -->
							<a href="">[arxiv]</a> <a href="code">[code]</a> 
							<br>
						</td>
					</tr>
					
					
					
					
					
					<tr>
						
						<td width="75%" valign="center",style="display:inline">
							<papertitle><strong>[2] Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory</strong></papertitle>
							<br>
							Li Siyao, Wenjiang Yu, <strong>Tianpei Gu</strong>, Chunze Lin, QUan Wang, Chen Qian, Chen Change Loy, Ziwen Liu
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<strong>CVPR</strong>)</em>, 2022
							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
							 								<img style="width:100%;max-width:100%" src="./images/pub/Bailando.pdf" alt="dise"> 
							 							</td> 
							
<!-- 							<br> -->
<!-- 							<td style="padding:20px;width:30%;max-width:30%" align="center"> -->
<!--  								<img style="width:100%;max-width:100%" src="images/pub/APNET.pdf" alt="dise"> --> 
<!--  							</td> -->
							<a href="">[arxiv]</a> <a href="code">[code]</a> 
							<br>
							<p></p>
							
						</td>
					</tr>
					
					
					
					
					
					
					<tr>
						
						<td width="75%" valign="center">
							<papertitle><strong>[3] Person Re-identification via Attention Pyramid</strong></papertitle>
							<br>
							Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-An Bao, and Jie Zhou
							<br>
							<em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2021
							<br>
 							<td style="padding:20px;width:30%;max-width:30%" align="center"> 
 								<img style="width:100%;max-width:100%" src="./images/pub/APNET.pdf" alt="dise"> 
 							</td> 
							<a href="https://chengy12.github.io/files/TIP-24326-2021R2.pdf">[PDF]</a> <a href="https://chengy12.github.io/files/TIP-24326-2021supp.pdf">[Supp]</a> <a href="https://github.com/gutianpei/APNet">[Code]</a> 
							<br>
							<p></p>
							<p>We propose attention pyramid networks by the "split-attend-merge-stack" principle to jointly learn the attentions under different scales and obtain superior performance on many person re-identification datasets.
							</p>
						</td>
					</tr>
			
			
			</td>
<!-- 			<td width="75%" valign="center"> -->
<!-- 				<strong>[2] Learnable Re-Ranking for Image Retrieval</strong> -->
<!-- 				<br> -->
<!-- 				<strong>Tianpei Gu</strong>, Guangyi Chen, Jiwen Lu, Jie Zhou -->
<!-- 				<br> -->
<!-- 				<em>Submitted to the IEEE/CVF International Conference on Computer Vision(<strong>ICCV</strong>), 2021</em> -->
<!-- 				<p>We proposed a Graph Neural Network to formulate re-ranking as a learnable process.</p> -->
<!-- 			</td> -->
<!-- 			 -->
<!-- 			 -->
<!-- 			<h1>Research Experience</h1> -->
<!-- 			<h2>Current Project</h2>	 -->
<!-- 			<h3>Diffusion Model for Generative Task</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Exploring the Diffusion Probabilistic Models.</li> -->
<!--  -->
<!-- 			</ul> -->
<!-- 			 -->
<!-- 			<h3>Image Editting and Latent Space</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Exploring the latent space of GAN. Now researching on CLIP-based editing methods.</li> -->
<!--  -->
<!-- 			</ul> -->
<!-- 			 -->
<!-- 			<h3>Music to Dance</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Generating 3D dance pose from input music.</li> -->
<!--  -->
<!-- 			</ul> -->
<!-- 			 -->
<!-- 			 -->
<!-- 			 -->
<!-- 			 -->
<!-- 			<h2>Past Project</h2>		 -->
<!-- 			<h3>3-D Reconstruction</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Researching on state-of-art 3D Reconstruction method, especially reconstruct with <a href="https://smpl.is.tue.mpg.de/">SMPL model</a>.</li> -->
<!-- 				<li>Customized existing 3D construction methods to fit our dataset; maintained the human 3D reconstruction methods survey for the lab. </li> -->
<!-- 			</ul> -->
<!-- 			 -->
<!-- 			<h3>Image-to-Image Translation</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Completely replicated the result of the paper U-GAT-IT and AniGAN and implement the model to real-world products. Both methods have no open-sourced code in Pytorch and I implement them from scratch</li> -->
<!-- 				<li>Ongoing</li> -->
<!-- 			</ul> -->
			
<!-- 			<h3>Person Re-identification</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Proposed a novel CNN-based network to re-identify person based on their movement style. </li> -->
<!-- 				<li>Built an online and in-memory system to re-identify people with 85% accuracy under clean image setting.</li> -->
<!-- 				<li>Propose to draw the counterfactual causality from the traditional trained "biased" network to infer the effect from bad bias, then remove them. Proposed a novel deep neural network for Person Re-ID task to make causal intervention in training and counterfactual reasoning in inference to remove the bad while keep the good features. </li> -->
<!-- 				<li>Proposed an attention pyramid structure for Person Re-ID task to focus more on local attention of the feature map while keep the global attention of a human image. Our method outperforms the state-of-the-art methods by a large margin with -40% computational cost. The work has been submitted to TIP.</li> -->
<!-- 			</ul> -->
			
<!-- 			<h3>Text-based Person Search</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Proposed a novel CNN-based network for text-based person search, using Resnet50 and Bi-LSTM as backbone network</li> -->
<!-- 				<li>Improved performance by adding Batch Normalization and Instance Normalization layers into our network and employing the triplet loss as the loss function. Our method outperforms the current state-of-the-art methods.</li> -->
<!-- 			</ul> -->
			
			
			<h1>Field Experience</h1>
			
			<h3>SenseTime Research</h3>
			Computer Vision Research Intern
			<ul>
				<li>Build an end-to-end image generation pipeline with StyleGAN to produce massive high-quality stylized image with model blending.</li>
				<li>Main contributor of the product which transferring human face image into multiple style (now 10+).</li>
				<li>Develop a pipeline of “Inversion-Editing-Stylization” for human face, which the editing part can receive a certain attribute selection or a text prompt.</li>
				<li>Assisted to implement the project of music to dance generation</li>
			</ul>

			
			
			
			<h3>Beijing Photon Dance Tech Inc.</h3>
			Co-Founder, Algorithm Engineer
			<ul>
				<li>Founded in Skywork Team, Tsinghua University.</li>
				<li>Proposed an end-to-end solution from extracted 3D point cloud with multiple views to automatic motion difference evaluating. Participated in multi-view point cloud calibration and developing of DL-based merging algorithm.</li>
				<li>Our team just receive the Pre-A Investment.</li>
			</ul>

			<h1>Professional Skills</h1>
			<p><b>Programming Language (ranked by proficiency):</b> Python, Java, C, C++, Matlab, Git, Shell</p>
			<p><b>Deep Learning Framework:</b> Keras, PyTorch, TensorFlow </p>

			<h1>Service</h1>
				<li>Reviewer for CVPR2022</li>
		</section>
		<footer>
			<p>
				<small>
					Hosted on GitHub Pages &mdash;
					Theme by <a href="https://github.com/orderedlist" , target="_blank">orderedlist</a>.
					<!-- <span id="busuanzi_container_site_pv" style='display:none'>
						Viewed <span id="busuanzi_value_site_pv"></span> times.
					</span> -->
				</small>
			</p>
		</footer>
	</div>
	<script src="javascripts/scale.fix.js"></script>
	<script async src="http://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>
</body>

</html>
