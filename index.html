
<!doctype html>
<html>

<head>
	<meta name="google-site-verification" content="zTvaPIARk2z5erZsE_yyEIuPe3r5Z1kwHtZ662ncmLU" />
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>Tianpei Gu 顾天培</title>

	<link rel="stylesheet" href="stylesheets/styles.css">
	<link rel="stylesheet" href="stylesheets/pygment_trac.css">
	<meta name="viewport" content="width=device-width">
	<link rel="icon" type="image/png" href="images/icon.png">
	<!--[if lt IE 9]>
		<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
</head>

<body>
	<div class="wrapper">
		<header>
			<h2>Tianpei Gu 「顾天培」</h2>
			<p></p>
<!-- 			<p>Research Ass @ Tsinghua University</p> -->
<!-- 			<p>Research Intern @ SenseTime Research</p> -->
			<img src="images/tianpei.JPG" alt="Photo @ UMD.">
			<p>
				<b>Email:</b> <a href="mailto:brucegu@umd.edu">gutianpei@ucla.edu</a><br>
				<b>Github:</b> <a href="https://github.com/Gutianpei" , target="_blank">https://github.com/Gutianpei</a><br>
				<b>LinkedIn:</b> <a href="https://www.linkedin.com/in/tianpei-gu-973904129/ ,
					target="_blank">https://www.linkedin.com/in/tianpei-gu-973904129/</a><br>
			</p>
			<img src="images/umd.jpg" alt="umd." height=63 weight = 63>
			<img src="images/thu.png" alt="thu." height=60 weight = 60>
			<img src="images/ucla.png" alt="ucla." height=60 weight = 60>


		</header>
		<section>
			<h1>About Me</h1>
			<p> I'm a final year Master student at <b>UCLA</b>, working closely with <a href="https://boleizhou.github.io/">Prof. Bolei Zhou</a>. I did research at <a href="http://ivg.au.tsinghua.edu.cn/">Intelligent Vision Group (IVG)</a>,  <b>Tsinghua University</b>, under the guidance of <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a> and <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Dr. Guangyi Chen</a>. I also worked at <b>SenseTime Research</b> as an intern. In December 2020, I received B.S. degree in Computer Science and Mathematics at the <b>University of Maryland</b>.
				My research interest is in <b>Computer Vision</b>, especially <b>Diffusion Models</b> and <b>Generative Modeling</b>.
				<!-- 				You can find my <a href="docs/GTP CV.pdf" target="_blank">resume</a> here. -->
			</p>
			<h1>News</h1>
			<ul>
				<li>2022-10: I'll join OPPO US Research as an intern.
				<li>2022-03: Two papers (1 oral and 1 poster) accepted to <b>CVPR'22</b>!</li>
				<li>2022-01: I move to LA for Master degree at UCLA.</li>
				<li>2022-03: Start an internship at SenseTime Research!</li>
				<li>2021-03: One paper accepted by <b>TIP'21</b>!</li>
			</ul>

			<h1>Education</h1>

			<h3>University of California, Los Angeles, CA, USA</h3>
			<ul>
				<li>Master of Engineering, Expected: August 2022</li>
				<li>TA for computer vision course</li>
			</ul>

			<h3>University of Maryland at College Park, MD, USA</h3>
			<ul>
				<li>Bachelor of Science in Computer Science</li>
				<li>Bachelor of Science in Mathematics</li>
			</ul>

			<h1>Publications</h1>
			<td width="100%" valign="center",style="white-space:nowrap;">
<!-- 				<strong>[1] Person Re-Identification via Attention Pyramid</strong> -->
<!-- 				<br> -->
<!-- 				Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-an Bao, Jie Zhou -->
<!-- 				<br> -->
<!-- 				<em>Submitted to IEEE Transcations on Image Processing(<strong>TIP</strong>), 2020</em> -->
<!-- 				<p>We designed a novel attention pyarmid structure to help the network focus more on local feature while keep the global representation.</p> -->

					<tr>

						<td width="75%" valign="center",style="white-space:nowrap;">
							<papertitle><strong>[1] Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion</strong></papertitle>
							<br>
							<strong>Tianpei Gu</strong>*, <a href="https://chengy12.github.io/">Guangyi Chen</a>*, Junlong Li, <a href="https://linchunze.github.io/">Chunze Lin</a>, <a href="https://raoyongming.github.io/">Yongming Rao</a>, <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>, <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<b><strong>CVPR</strong></b>)</em>, 2022, (<strong>Poster</strong>)
							<td style="padding:20px;width:30%;max-width:30%" align="center">
							 								<img style="width:100%;max-width:100%;height:50" src="/images/pub/MID.png" alt="dise">
							 							</td>

							<a href="https://arxiv.org/abs/2203.13777">[Arxiv]</a> <a href="https://github.com/Gutianpei/MID">[Code]</a>
							<br>
							<p>We propose a new framework to formulate the trajectory prediction task as a reverse process of motion interminacy diffusion, in which we progressively discard indeterminacy from all the walkable areas until reaching the desired trajectory.
							</p>
						</td>
					</tr>


					<tr>

						<td width="75%" valign="center",style="display:inline">
							<papertitle><strong>[2] Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory</strong></papertitle>
							<br>
							<a href="lisiyao21.github.io">Li Siyao</a>, Wenjiang Yu, <strong>Tianpei Gu</strong>, <a href="https://linchunze.github.io/">Chunze Lin</a>, Quan Wang, Chen Qian, <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Chang Loy</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
							<br>
							<em>IEEE/CVF Conference on Computer Vision and Patter Recognition (<strong>CVPR</strong>)</em>, 2022, (<strong>Oral</strong>)
							<td style="padding:20px;width:30%;max-width:30%" align="center">
							 	<img style="width:100%;max-width:100%" src="/images/pub/Bailando.png" alt="dise">
							 </td>
							<a href="https://arxiv.org/abs/2203.13055">[Arxiv]</a> <a href="https://github.com/lisiyao21/Bailando/">[Code]</a>
							<br>
							<p></p>

						</td>
					</tr>






					<tr>

						<td width="75%" valign="center">
							<papertitle><strong>[3] Person Re-identification via Attention Pyramid</strong></papertitle>
							<br>
							<a href="https://chengy12.github.io/">Guangyi Chen</a>, <strong>Tianpei Gu</strong>, <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>, Jin-An Bao,<a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1"> Jie Zhou </a>

							<br>
							<em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2021
							<br>
 							<td style="padding:20px;width:30%;max-width:30%" align="center">
 								<img style="width:100%;max-width:100%" src="/images/pub/APNET.png" alt="dise">
 							</td>
							<a href="https://chengy12.github.io/files/TIP-24326-2021R2.pdf">[PDF]</a> <a href="https://chengy12.github.io/files/TIP-24326-2021supp.pdf">[Supp]</a> <a href="https://github.com/gutianpei/APNet">[Code]</a>
							<br>
							<p>We propose attention pyramid networks by the "split-attend-merge-stack" principle to jointly learn the attentions under different scales and obtain superior performance on many person re-identification datasets.
							</p>
						</td>
					</tr>


			</td>



			<h1>Field Experience</h1>

			<h3>SenseTime Research</h3>
			Computer Vision Research Intern
			<ul>
				<li>Build an end-to-end image generation pipeline with StyleGAN to produce massive high-quality stylized image with model blending.</li>
				<li>Main contributor of the product which transferring human face image into multiple style (now 10+).</li>
				<li>Develop a pipeline of “Inversion-Editing-Stylization” for human face, which the editing part can receive a certain attribute selection or a text prompt.</li>
				<li>Assisted to implement the project of music to dance generation</li>
			</ul>

			<h1>Service</h1>
			<ul>
				<li>Reviewer for CVPR2022</li>
			</ul>

			<h1>Professional Skills</h1>
			<p><b>Programming Language (ranked by proficiency):</b> Python, Java, C, C++, Matlab, Git, Shell</p>
			<p><b>Deep Learning Framework:</b> PyTorch, Keras, Tensorflow</p>



	</div>
	<script src="javascripts/scale.fix.js"></script>
	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>
</body>

</html>
